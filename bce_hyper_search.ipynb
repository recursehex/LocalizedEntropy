{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# BCE Hyperparameter Search (`ler` / epochs)\n",
        "\n",
        "This notebook runs a BCE-only hyperparameter search using `configs/default.json` exactly as-is.\n",
        "\n",
        "- Outer loop: learning rate (`ler`) starts at `1.0` and halves each step.\n",
        "- Inner loop: train for `10` epochs and evaluate at every epoch.\n",
        "- Evaluation at each epoch collects:\n",
        "  - BCE on test/eval split\n",
        "  - Global calibration ratio on eval/test split only\n",
        "  - Per-category (condition) calibration ratio on eval/test split only\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "880d1a2f",
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "from __future__ import annotations\n",
        "\n",
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from localized_entropy.analysis import bce_log_loss, per_condition_calibration\n",
        "from localized_entropy.config import load_and_resolve, get_data_source, resolve_ctr_config\n",
        "from localized_entropy.data.pipeline import prepare_data\n",
        "from localized_entropy.experiments import build_loss_loaders, build_model, train_single_loss\n",
        "from localized_entropy.training import predict_probs\n",
        "from localized_entropy.utils import init_device, set_seed\n",
        "\n",
        "np.set_printoptions(precision=6, suppress=True)\n",
        "pd.set_option(\"display.max_rows\", 200)\n",
        "pd.set_option(\"display.max_columns\", 50)\n",
        "\n",
        "CONFIG_PATH = \"configs/hyper.json\"\n",
        "cfg = load_and_resolve(CONFIG_PATH)\n",
        "\n",
        "device_cfg = cfg.get(\"device\", {})\n",
        "device, use_cuda, use_mps, non_blocking = init_device(use_mps=bool(device_cfg.get(\"use_mps\", True)))\n",
        "cpu_float64 = device.type == \"cpu\" and not bool(device_cfg.get(\"use_mps\", True))\n",
        "model_dtype = torch.float64 if cpu_float64 else torch.float32\n",
        "\n",
        "set_seed(int(cfg[\"project\"][\"seed\"]), use_cuda)\n",
        "prepared = prepare_data(cfg, device, use_cuda, use_mps)\n",
        "splits = prepared.splits\n",
        "\n",
        "loss_loaders, bce_train_cfg = build_loss_loaders(cfg, \"bce\", splits, device, use_cuda, use_mps)\n",
        "data_source = get_data_source(cfg)\n",
        "\n",
        "test_has_labels = not (data_source == \"ctr\" and not bool(resolve_ctr_config(cfg).get(\"test_has_labels\", False)))\n",
        "if loss_loaders.test_loader is not None and splits.y_test is not None and test_has_labels:\n",
        "    eval_loader = loss_loaders.test_loader\n",
        "    eval_labels = np.asarray(splits.y_test).reshape(-1)\n",
        "    eval_conds = np.asarray(splits.c_test).reshape(-1)\n",
        "    eval_name = \"test\"\n",
        "else:\n",
        "    eval_loader = loss_loaders.eval_loader\n",
        "    eval_labels = np.asarray(splits.y_eval).reshape(-1)\n",
        "    eval_conds = np.asarray(splits.c_eval).reshape(-1)\n",
        "    eval_name = \"eval\"\n",
        "\n",
        "print(f\"Evaluation split for BCE loss: {eval_name}\")\n",
        "print(f\"Data source: {data_source}\")\n",
        "print(f\"Num conditions/categories: {splits.num_conditions}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "464207f7",
      "metadata": {},
      "outputs": [],
      "source": [
        "def lr_schedule_halving(start: float = 1.0, floor: float = 1e-6):\n",
        "    if floor <= 0:\n",
        "        raise ValueError(\"floor must be > 0\")\n",
        "    values = []\n",
        "    lr = float(start)\n",
        "    while lr >= floor:\n",
        "        values.append(lr)\n",
        "        lr = lr / 2.0\n",
        "    if not values:\n",
        "        raise ValueError(f\"No learning rates generated: start={start} floor={floor}\")\n",
        "    return values\n",
        "\n",
        "\n",
        "def _global_calibration_ratio(preds: np.ndarray, labels: np.ndarray, eps: float = 1e-12) -> float:\n",
        "    pred_mean = float(np.mean(preds))\n",
        "    label_mean = float(np.mean(labels))\n",
        "    if label_mean <= eps:\n",
        "        return float(\"nan\")\n",
        "    return pred_mean / label_mean\n",
        "\n",
        "\n",
        "def collect_all_data_metrics(model: torch.nn.Module) -> tuple[float, pd.DataFrame]:\n",
        "    eval_preds_for_cal = predict_probs(model, eval_loader, device, non_blocking=non_blocking)\n",
        "    eval_preds_for_cal = np.asarray(eval_preds_for_cal, dtype=np.float64).reshape(-1)\n",
        "\n",
        "    if eval_preds_for_cal.shape[0] != eval_labels.shape[0] or eval_preds_for_cal.shape[0] != eval_conds.shape[0]:\n",
        "        raise ValueError(\n",
        "            f\"Mismatched eval lengths: preds={eval_preds_for_cal.shape[0]} labels={eval_labels.shape[0]} conds={eval_conds.shape[0]}\"\n",
        "        )\n",
        "\n",
        "    global_calibration = _global_calibration_ratio(eval_preds_for_cal, eval_labels)\n",
        "    per_cond = per_condition_calibration(eval_preds_for_cal, eval_labels, eval_conds)\n",
        "    return global_calibration, per_cond\n",
        "\n",
        "\n",
        "LEARNING_RATES = lr_schedule_halving(start=0.1, floor=0.00001)\n",
        "EPOCHS = 15\n",
        "\n",
        "print(f\"Number of LR points: {len(LEARNING_RATES)}\")\n",
        "print(\"First/last LR:\", LEARNING_RATES[0], LEARNING_RATES[-1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "608aa4e6",
      "metadata": {},
      "outputs": [],
      "source": [
        "epoch_records = []\n",
        "condition_records = []\n",
        "\n",
        "for lr in LEARNING_RATES:\n",
        "    set_seed(int(cfg[\"project\"][\"seed\"]), use_cuda)\n",
        "    model = build_model(cfg, splits, device, dtype=model_dtype)\n",
        "\n",
        "    def on_epoch_eval(eval_preds: np.ndarray, epoch: int) -> None:\n",
        "        test_bce = bce_log_loss(eval_preds.reshape(-1), eval_labels)\n",
        "        global_calibration, per_cond_df = collect_all_data_metrics(model)\n",
        "        print(f\"[CAL] lr={float(lr):.6g} epoch={int(epoch)} global={float(global_calibration):.6f}\")\n",
        "        if per_cond_df.empty:\n",
        "            print(f\"[CAL] lr={float(lr):.6g} epoch={int(epoch)} per-condition: <none>\")\n",
        "        else:\n",
        "            cal_pairs = \", \".join(\n",
        "                f\"c{int(r.condition)}={float(r.calibration):.6f}\"\n",
        "                for r in per_cond_df.sort_values(\"condition\").itertuples(index=False)\n",
        "            )\n",
        "            print(f\"[CAL] lr={float(lr):.6g} epoch={int(epoch)} per-condition: {cal_pairs}\")\n",
        "\n",
        "        epoch_records.append(\n",
        "            {\n",
        "                \"lr\": float(lr),\n",
        "                \"epoch\": int(epoch),\n",
        "                \"test_bce\": float(test_bce),\n",
        "                \"global_calibration\": float(global_calibration),\n",
        "            }\n",
        "        )\n",
        "\n",
        "        for _, row in per_cond_df.iterrows():\n",
        "            condition_records.append(\n",
        "                {\n",
        "                    \"lr\": float(lr),\n",
        "                    \"epoch\": int(epoch),\n",
        "                    \"condition\": int(row[\"condition\"]),\n",
        "                    \"count\": int(row[\"count\"]),\n",
        "                    \"base_rate\": float(row[\"base_rate\"]),\n",
        "                    \"pred_mean\": float(row[\"pred_mean\"]),\n",
        "                    \"calibration\": float(row[\"calibration\"]),\n",
        "                }\n",
        "            )\n",
        "\n",
        "    _ = train_single_loss(\n",
        "        model=model,\n",
        "        loss_mode=\"bce\",\n",
        "        train_loader=loss_loaders.train_loader,\n",
        "        train_eval_loader=eval_loader,\n",
        "        eval_loader=eval_loader,\n",
        "        device=device,\n",
        "        epochs=EPOCHS,\n",
        "        lr=float(lr),\n",
        "        eval_has_labels=True,\n",
        "        non_blocking=non_blocking,\n",
        "        eval_callback=on_epoch_eval,\n",
        "        plot_eval_hist_epochs=False,\n",
        "        print_embedding_table=False,\n",
        "    )\n",
        "\n",
        "results_df = pd.DataFrame(epoch_records)\n",
        "condition_df = pd.DataFrame(condition_records)\n",
        "\n",
        "if results_df.empty:\n",
        "    raise RuntimeError(\"Search produced no results.\")\n",
        "\n",
        "results_df = results_df.sort_values([\"test_bce\", \"lr\", \"epoch\"], ascending=[True, True, True]).reset_index(drop=True)\n",
        "best_row = results_df.iloc[0]\n",
        "\n",
        "print(\"Best BCE result:\")\n",
        "print(best_row.to_dict())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "342f861c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_metric_lines(metric_df: pd.DataFrame, value_col: str, title: str, y_label: str) -> None:\n",
        "    plt.figure(figsize=(11, 6))\n",
        "    lr_order = sorted(metric_df[\"lr\"].unique(), reverse=True)\n",
        "    for lr in lr_order:\n",
        "        block = metric_df.loc[metric_df[\"lr\"] == lr, [\"epoch\", value_col]].sort_values(\"epoch\")\n",
        "        plt.plot(\n",
        "            block[\"epoch\"],\n",
        "            block[value_col],\n",
        "            marker=\"o\",\n",
        "            linewidth=1.5,\n",
        "            markersize=3,\n",
        "            label=f\"ler={lr:.6g}\",\n",
        "        )\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(y_label)\n",
        "    plt.title(title)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.legend(ncol=3, fontsize=8)\n",
        "    if \"calibration\" in value_col.lower():\n",
        "        plt.ylim(0, 3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def display_sortable_table(df: pd.DataFrame, table_id: str = \"bce_final_results\") -> None:\n",
        "    from IPython.display import HTML, display\n",
        "\n",
        "    html_table = df.to_html(index=False, table_id=table_id, classes=\"display compact\", border=0)\n",
        "    html = f\"\"\"\n",
        "<link rel=\"stylesheet\" href=\"https://cdn.datatables.net/1.13.8/css/jquery.dataTables.min.css\" />\n",
        "<script src=\"https://code.jquery.com/jquery-3.7.1.min.js\"></script>\n",
        "<script src=\"https://cdn.datatables.net/1.13.8/js/jquery.dataTables.min.js\"></script>\n",
        "{html_table}\n",
        "<script>\n",
        "(function() {{\n",
        "  var tableId = '#{table_id}';\n",
        "  if (window.jQuery && jQuery.fn && jQuery.fn.DataTable) {{\n",
        "    if (jQuery.fn.DataTable.isDataTable(tableId)) {{\n",
        "      jQuery(tableId).DataTable().destroy();\n",
        "    }}\n",
        "    jQuery(tableId).DataTable({{\n",
        "      paging: true,\n",
        "      pageLength: 100,\n",
        "      lengthMenu: [[25, 50, 100, -1], [25, 50, 100, 'All']],\n",
        "      ordering: true,\n",
        "      info: true,\n",
        "      autoWidth: false,\n",
        "      scrollX: true\n",
        "    }});\n",
        "  }}\n",
        "}})();\n",
        "</script>\n",
        "\"\"\"\n",
        "    display(HTML(html))\n",
        "\n",
        "\n",
        "table_cols = [\"lr\", \"epoch\", \"test_bce\", \"global_calibration\"]\n",
        "final_table_df = results_df.copy()\n",
        "\n",
        "# Show all rows/columns in a sortable table (with pandas fallback).\n",
        "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
        "    try:\n",
        "        display_sortable_table(final_table_df, table_id=\"bce_final_results\")\n",
        "    except Exception as exc:\n",
        "        print(f\"[WARN] Sortable table renderer unavailable ({exc}); falling back to plain display.\")\n",
        "        display(final_table_df)\n",
        "\n",
        "print(\"Most optimal ler (by minimum test_bce):\", float(best_row[\"lr\"]))\n",
        "print(\"Best epoch for that ler:\", int(best_row[\"epoch\"]))\n",
        "print(\"Best test_bce:\", float(best_row[\"test_bce\"]))\n",
        "\n",
        "# Chart 1: BCE across learning rate and epochs\n",
        "plot_metric_lines(\n",
        "    metric_df=results_df,\n",
        "    value_col=\"test_bce\",\n",
        "    title=f\"BCE ({eval_name}) across learning rate and epoch\",\n",
        "    y_label=\"BCE\",\n",
        ")\n",
        "\n",
        "# Chart 2: Global calibration across learning rate and epochs\n",
        "plot_metric_lines(\n",
        "    metric_df=results_df,\n",
        "    value_col=\"global_calibration\",\n",
        "    title=\"Global calibration ratio across learning rate and epoch\",\n",
        "    y_label=\"Calibration ratio\",\n",
        ")\n",
        "\n",
        "# Chart 3: Per-condition calibration charts\n",
        "# Per-condition calibration table used for charts\n",
        "condition_table_cols = [\"lr\", \"epoch\", \"condition\", \"count\", \"base_rate\", \"pred_mean\", \"calibration\"]\n",
        "display(condition_df.loc[:, condition_table_cols].sort_values([\"condition\", \"lr\", \"epoch\"]).reset_index(drop=True))\n",
        "\n",
        "if condition_df.empty:\n",
        "    print(\"No per-condition records to plot.\")\n",
        "else:\n",
        "    cond_ids = sorted(condition_df[\"condition\"].unique())\n",
        "    n = len(cond_ids)\n",
        "    ncols = 3\n",
        "    nrows = int(math.ceil(n / ncols))\n",
        "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(5 * ncols, 3.8 * nrows))\n",
        "    axes = np.array(axes).reshape(-1)\n",
        "\n",
        "    lr_order = sorted(condition_df[\"lr\"].unique(), reverse=True)\n",
        "    epoch_order = sorted(condition_df[\"epoch\"].unique())\n",
        "\n",
        "    for i, cond_id in enumerate(cond_ids):\n",
        "        ax = axes[i]\n",
        "        block = condition_df.loc[condition_df[\"condition\"] == cond_id, [\"lr\", \"epoch\", \"calibration\"]]\n",
        "        ax.set_title(f\"Condition {cond_id}\")\n",
        "        for lr in lr_order:\n",
        "            lr_block = block.loc[block[\"lr\"] == lr, [\"epoch\", \"calibration\"]].sort_values(\"epoch\")\n",
        "            if lr_block.empty:\n",
        "                continue\n",
        "            ax.plot(\n",
        "                lr_block[\"epoch\"],\n",
        "                lr_block[\"calibration\"],\n",
        "                marker=\"o\",\n",
        "                linewidth=1.2,\n",
        "                markersize=2.5,\n",
        "                label=f\"{lr:.3g}\",\n",
        "            )\n",
        "        ax.set_xticks(epoch_order)\n",
        "        ax.set_xlabel(\"Epoch\")\n",
        "        ax.set_ylabel(\"Calibration\")\n",
        "        ax.set_ylim(0, 2)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.legend(fontsize=6)\n",
        "\n",
        "    for j in range(len(cond_ids), len(axes)):\n",
        "        axes[j].axis(\"off\")\n",
        "\n",
        "    fig.suptitle(\"Per-condition calibration ratio across epoch (line per ler)\")\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
