{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LE Hyperparameter Search (Batch Size / Epochs)\n",
    "\n",
    "This notebook runs a Localized Entropy (LE) hyperparameter search using `configs/hyper.json` and sweeps `batch_size` with fixed `epochs=5`.\n",
    "\n",
    "- Outer loop: `batch_size` grid\n",
    "- Inner loop: train for `5` epochs and evaluate each epoch\n",
    "- Per-epoch collection:\n",
    "  - LE loss on test/eval split\n",
    "  - Global calibration ratio on eval/test split only\n",
    "  - Per-condition calibration ratio on eval/test split only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import annotations\n",
    "\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from localized_entropy.config import get_data_source, load_and_resolve, resolve_ctr_config\n",
    "from localized_entropy.data.pipeline import prepare_data\n",
    "from localized_entropy.experiments import build_loss_loaders, build_model, train_single_loss\n",
    "from localized_entropy.training import compute_base_rates_from_loader, evaluate, predict_probs\n",
    "from localized_entropy.analysis import per_condition_calibration\n",
    "from localized_entropy.utils import init_device, set_seed\n",
    "\n",
    "np.set_printoptions(precision=6, suppress=True)\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "CONFIG_PATH = \"configs/hyper.json\"\n",
    "cfg = load_and_resolve(CONFIG_PATH)\n",
    "\n",
    "device_cfg = cfg.get(\"device\", {})\n",
    "device, use_cuda, use_mps, non_blocking = init_device(use_mps=bool(device_cfg.get(\"use_mps\", True)))\n",
    "cpu_float64 = device.type == \"cpu\" and not bool(device_cfg.get(\"use_mps\", True))\n",
    "model_dtype = torch.float64 if cpu_float64 else torch.float32\n",
    "\n",
    "set_seed(int(cfg[\"project\"][\"seed\"]), use_cuda)\n",
    "prepared = prepare_data(cfg, device, use_cuda, use_mps)\n",
    "splits = prepared.splits\n",
    "\n",
    "data_source = get_data_source(cfg)\n",
    "test_has_labels = not (data_source == \"ctr\" and not bool(resolve_ctr_config(cfg).get(\"test_has_labels\", False)))\n",
    "\n",
    "print(f\"Data source: {data_source}\")\n",
    "print(f\"Num conditions/categories: {splits.num_conditions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _global_calibration_ratio(preds: np.ndarray, labels: np.ndarray, eps: float = 1e-12) -> float:\n",
    "    pred_mean = float(np.mean(preds))\n",
    "    label_mean = float(np.mean(labels))\n",
    "    if label_mean <= eps:\n",
    "        return float(\"nan\")\n",
    "    return pred_mean / label_mean\n",
    "\n",
    "\n",
    "def collect_all_data_metrics(model: torch.nn.Module, eval_loader, eval_labels: np.ndarray, eval_conds: np.ndarray):\n",
    "    eval_preds = predict_probs(model, eval_loader, device, non_blocking=non_blocking)\n",
    "    eval_preds = np.asarray(eval_preds, dtype=np.float64).reshape(-1)\n",
    "\n",
    "    if eval_preds.shape[0] != eval_labels.shape[0] or eval_preds.shape[0] != eval_conds.shape[0]:\n",
    "        raise ValueError(\n",
    "            f\"Mismatched eval lengths: preds={eval_preds.shape[0]} labels={eval_labels.shape[0]} conds={eval_conds.shape[0]}\"\n",
    "        )\n",
    "\n",
    "    global_calibration = _global_calibration_ratio(eval_preds, eval_labels)\n",
    "    per_cond = per_condition_calibration(eval_preds, eval_labels, eval_conds)\n",
    "    return global_calibration, per_cond\n",
    "\n",
    "\n",
    "BATCH_SIZES = [4096, 8192, 16384, 25000, 32768, 65536]\n",
    "EPOCHS = 5\n",
    "\n",
    "print(\"Batch sizes to try:\", BATCH_SIZES)\n",
    "print(\"Epochs per run:\", EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_records = []\n",
    "condition_records = []\n",
    "\n",
    "for batch_size in BATCH_SIZES:\n",
    "    cfg_run = copy.deepcopy(cfg)\n",
    "    cfg_run.setdefault(\"training\", {})\n",
    "    cfg_run[\"training\"][\"epochs\"] = int(EPOCHS)\n",
    "    cfg_run[\"training\"][\"batch_size\"] = int(batch_size)\n",
    "\n",
    "    # Ensure per-source LE overrides use this sweep value where present.\n",
    "    le_by_source = cfg_run.get(\"training\", {}).get(\"by_loss\", {}).get(\"localized_entropy\", {}).get(\"by_source\", {})\n",
    "    for src_name, src_cfg in le_by_source.items():\n",
    "        if isinstance(src_cfg, dict):\n",
    "            src_cfg[\"epochs\"] = int(EPOCHS)\n",
    "            src_cfg[\"batch_size\"] = int(batch_size)\n",
    "\n",
    "    loss_loaders, le_train_cfg = build_loss_loaders(cfg_run, \"localized_entropy\", splits, device, use_cuda, use_mps)\n",
    "\n",
    "    if loss_loaders.test_loader is not None and splits.y_test is not None and test_has_labels:\n",
    "        eval_loader = loss_loaders.test_loader\n",
    "        eval_labels = np.asarray(splits.y_test).reshape(-1)\n",
    "        eval_conds = np.asarray(splits.c_test).reshape(-1)\n",
    "        eval_name = \"test\"\n",
    "    else:\n",
    "        eval_loader = loss_loaders.eval_loader\n",
    "        eval_labels = np.asarray(splits.y_eval).reshape(-1)\n",
    "        eval_conds = np.asarray(splits.c_eval).reshape(-1)\n",
    "        eval_name = \"eval\"\n",
    "\n",
    "    first_param_dtype = torch.float64 if cpu_float64 else torch.float32\n",
    "    base_rates_train = compute_base_rates_from_loader(\n",
    "        loss_loaders.train_loader,\n",
    "        num_conditions=int(splits.num_conditions),\n",
    "        device=device,\n",
    "        dtype=first_param_dtype,\n",
    "        non_blocking=non_blocking,\n",
    "    )\n",
    "\n",
    "    set_seed(int(cfg_run[\"project\"][\"seed\"]), use_cuda)\n",
    "    model = build_model(cfg_run, splits, device, dtype=model_dtype)\n",
    "\n",
    "    def on_epoch_eval(_eval_preds: np.ndarray, epoch: int, bs: int = int(batch_size)) -> None:\n",
    "        le_loss, _ = evaluate(\n",
    "            model,\n",
    "            eval_loader,\n",
    "            device,\n",
    "            loss_mode=\"localized_entropy\",\n",
    "            base_rates=base_rates_train,\n",
    "            non_blocking=non_blocking,\n",
    "        )\n",
    "        global_calibration, per_cond_df = collect_all_data_metrics(model, eval_loader, eval_labels, eval_conds)\n",
    "\n",
    "        epoch_records.append(\n",
    "            {\n",
    "                \"batch_size\": int(bs),\n",
    "                \"epoch\": int(epoch),\n",
    "                \"test_le\": float(le_loss),\n",
    "                \"global_calibration\": float(global_calibration),\n",
    "                \"eval_split\": eval_name,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        for _, row in per_cond_df.iterrows():\n",
    "            condition_records.append(\n",
    "                {\n",
    "                    \"batch_size\": int(bs),\n",
    "                    \"epoch\": int(epoch),\n",
    "                    \"condition\": int(row[\"condition\"]),\n",
    "                    \"count\": int(row[\"count\"]),\n",
    "                    \"base_rate\": float(row[\"base_rate\"]),\n",
    "                    \"pred_mean\": float(row[\"pred_mean\"]),\n",
    "                    \"calibration\": float(row[\"calibration\"]),\n",
    "                }\n",
    "            )\n",
    "\n",
    "    train_single_loss(\n",
    "        model=model,\n",
    "        loss_mode=\"localized_entropy\",\n",
    "        train_loader=loss_loaders.train_loader,\n",
    "        train_eval_loader=eval_loader,\n",
    "        eval_loader=eval_loader,\n",
    "        device=device,\n",
    "        epochs=int(EPOCHS),\n",
    "        lr=float(le_train_cfg.get(\"lr\", cfg_run[\"training\"][\"lr\"])),\n",
    "        lr_category=le_train_cfg.get(\"lr_category\"),\n",
    "        lr_decay=float(le_train_cfg.get(\"lr_decay\", cfg_run.get(\"training\", {}).get(\"lr_decay\", 1.0))),\n",
    "        lr_category_decay=float(le_train_cfg.get(\"lr_category_decay\", cfg_run.get(\"training\", {}).get(\"lr_category_decay\", 1.0))),\n",
    "        lr_zero_after_epochs=le_train_cfg.get(\"lr_zero_after_epochs\"),\n",
    "        eval_has_labels=True,\n",
    "        le_base_rates_train=base_rates_train,\n",
    "        le_base_rates_train_eval=base_rates_train,\n",
    "        le_base_rates_eval=base_rates_train,\n",
    "        non_blocking=non_blocking,\n",
    "        eval_callback=on_epoch_eval,\n",
    "        plot_eval_hist_epochs=False,\n",
    "        print_embedding_table=False,\n",
    "        le_cross_batch_cfg=copy.deepcopy(le_train_cfg.get(\"cross_batch\")) if isinstance(le_train_cfg.get(\"cross_batch\"), dict) else None,\n",
    "    )\n",
    "\n",
    "results_df = pd.DataFrame(epoch_records)\n",
    "condition_df = pd.DataFrame(condition_records)\n",
    "\n",
    "if results_df.empty:\n",
    "    raise RuntimeError(\"Search produced no results.\")\n",
    "\n",
    "results_df = results_df.sort_values([\"test_le\", \"batch_size\", \"epoch\"], ascending=[True, True, True]).reset_index(drop=True)\n",
    "best_row = results_df.iloc[0]\n",
    "\n",
    "print(f\"Evaluation split for LE loss: {best_row['eval_split']}\")\n",
    "print(\"Best LE result:\")\n",
    "print(best_row.to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_lines(metric_df: pd.DataFrame, value_col: str, title: str, y_label: str) -> None:\n",
    "    plt.figure(figsize=(11, 6))\n",
    "    batch_order = sorted(metric_df[\"batch_size\"].unique())\n",
    "    for batch_size in batch_order:\n",
    "        block = metric_df.loc[metric_df[\"batch_size\"] == batch_size, [\"epoch\", value_col]].sort_values(\"epoch\")\n",
    "        plt.plot(\n",
    "            block[\"epoch\"],\n",
    "            block[value_col],\n",
    "            marker=\"o\",\n",
    "            linewidth=1.5,\n",
    "            markersize=3,\n",
    "            label=f\"batch_size={int(batch_size)}\",\n",
    "        )\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(ncol=3, fontsize=8)\n",
    "    if \"calibration\" in value_col.lower():\n",
    "        plt.ylim(0, 3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "table_cols = [\"batch_size\", \"epoch\", \"test_le\", \"global_calibration\", \"eval_split\"]\n",
    "results_sorted = results_df.sort_values([\"test_le\", \"batch_size\", \"epoch\"], ascending=[True, True, True]).reset_index(drop=True)\n",
    "condition_sorted = condition_df.sort_values([\"condition\", \"batch_size\", \"epoch\"]).reset_index(drop=True)\n",
    "\n",
    "display(results_sorted.loc[:, table_cols].head(200))\n",
    "\n",
    "best_row = results_sorted.iloc[0]\n",
    "print(\"Most optimal batch_size (by minimum test_le):\", int(best_row[\"batch_size\"]))\n",
    "print(\"Best epoch for that batch_size:\", int(best_row[\"epoch\"]))\n",
    "print(\"Best test_le:\", float(best_row[\"test_le\"]))\n",
    "\n",
    "plot_metric_lines(\n",
    "    metric_df=results_sorted,\n",
    "    value_col=\"test_le\",\n",
    "    title=\"LE across batch size and epoch\",\n",
    "    y_label=\"LE loss\",\n",
    ")\n",
    "\n",
    "plot_metric_lines(\n",
    "    metric_df=results_sorted,\n",
    "    value_col=\"global_calibration\",\n",
    "    title=\"Global calibration ratio across batch size and epoch\",\n",
    "    y_label=\"Calibration ratio\",\n",
    ")\n",
    "\n",
    "condition_table_cols = [\"batch_size\", \"epoch\", \"condition\", \"count\", \"base_rate\", \"pred_mean\", \"calibration\"]\n",
    "display(condition_sorted.loc[:, condition_table_cols])\n",
    "\n",
    "if condition_sorted.empty:\n",
    "    print(\"No per-condition records to plot.\")\n",
    "else:\n",
    "    cond_ids = sorted(condition_sorted[\"condition\"].unique())\n",
    "    n = len(cond_ids)\n",
    "    ncols = 3\n",
    "    nrows = int(math.ceil(n / ncols))\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(5 * ncols, 3.8 * nrows))\n",
    "    axes = np.array(axes).reshape(-1)\n",
    "\n",
    "    batch_order = sorted(condition_sorted[\"batch_size\"].unique())\n",
    "    epoch_order = sorted(condition_sorted[\"epoch\"].unique())\n",
    "\n",
    "    for i, cond_id in enumerate(cond_ids):\n",
    "        ax = axes[i]\n",
    "        block = condition_sorted.loc[condition_sorted[\"condition\"] == cond_id, [\"batch_size\", \"epoch\", \"calibration\"]]\n",
    "        ax.set_title(f\"Condition {cond_id}\")\n",
    "        for batch_size in batch_order:\n",
    "            bs_block = block.loc[block[\"batch_size\"] == batch_size, [\"epoch\", \"calibration\"]].sort_values(\"epoch\")\n",
    "            if bs_block.empty:\n",
    "                continue\n",
    "            ax.plot(\n",
    "                bs_block[\"epoch\"],\n",
    "                bs_block[\"calibration\"],\n",
    "                marker=\"o\",\n",
    "                linewidth=1.2,\n",
    "                markersize=2.5,\n",
    "                label=f\"{int(batch_size)}\",\n",
    "            )\n",
    "        ax.set_xticks(epoch_order)\n",
    "        ax.set_xlabel(\"Epoch\")\n",
    "        ax.set_ylabel(\"Calibration\")\n",
    "        ax.set_ylim(0, 3)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend(fontsize=6)\n",
    "\n",
    "    for j in range(len(cond_ids), len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    fig.suptitle(\"Per-condition calibration ratio across epoch (line per batch size)\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
